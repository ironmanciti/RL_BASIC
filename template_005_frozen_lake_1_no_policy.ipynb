{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8820a4a2",
   "metadata": {},
   "source": [
    "# 005_frozen_lake_1_no_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247df1a8",
   "metadata": {},
   "source": [
    "```\n",
    "LEFT - 0, DOWN - 1, RIGHT - 2, UP - 3\n",
    "\n",
    "SFFF       (S: starting point, safe)\n",
    "FHFH       (F: frozen surface, safe)\n",
    "FFFH       (H: hole, fall to your doom)\n",
    "HFFG       (G: goal, where the frisbee is located)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6035c0",
   "metadata": {},
   "source": [
    "### Policy 학습 없는 상태로 random 하게 action 을 취할 경우 각 환경에서 agent 가 Goal 에 도달할 확률을 시각화\n",
    "\n",
    "- stochastic / deterministic 환경 비교  \n",
    "\n",
    "- FrozenLake-v1, FrozenLake8x8-v1 환경 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d503d18",
   "metadata": {},
   "source": [
    "### 특별한 policy 없이 random action 에 의해 이동할 경우 deterministic 환경과 stochastic 환경에서 goal 에 도달할 확률이 크게 차이나지 않음\n",
    "\n",
    "policy 없이 마구 헤매는 경우의 성공률 10 % 미만"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
